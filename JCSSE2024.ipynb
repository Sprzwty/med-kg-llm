{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ee9ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd092ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def divide_text_into_sentences(file_path):\n",
    "    # load English tokenizer, POS tagger, parser and NER\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "    with open(file_path, 'r') as f:\n",
    "        text = f.read()\n",
    "\n",
    "    # process the text\n",
    "    doc = nlp(text)\n",
    "\n",
    "    # write sentences to a CSV file\n",
    "    with open('Data.csv', 'w', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        for sentence in doc.sents:\n",
    "            writer.writerow([sentence.text])\n",
    "\n",
    "\n",
    "divide_text_into_sentences('RawText.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4336b4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import openai\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ca4222",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bfcca72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_information(file_path):\n",
    "    with open(file_path, 'r') as f:\n",
    "        text = f.read()\n",
    "    return text\n",
    "\n",
    "\n",
    "# def generate_triples(text):\n",
    "#     response = openai.Completion.create(\n",
    "#         # engine=\"gpt-3.5-turbo\",\n",
    "#         engine=\"text-davinci-003\",\n",
    "#         prompt=f\"Generate All the RDF triples for the information below in URI format by:'{text}'. Write every triple in a independent line please and you are allowed to adjust all the triples to use URLs from original sources. For Example:  ('<https://en.wikipedia.org/wiki/Acute_lymphoblastic_leukemia>', '<https://en.wikipedia.org/wiki/Property_(philosophy)>/typeOf>', '<https://en.wikipedia.org/wiki/Cancer>').\",\n",
    "#         temperature=0.5,\n",
    "#         max_tokens=3699\n",
    "#     )\n",
    "#     triple_text = response.choices[0].text.strip()\n",
    "#     return triple_text\n",
    "\n",
    "def generate_triples(text):\n",
    "    response = openai.Completion.create(\n",
    "        engine=\"text-davinci-003\",\n",
    "        prompt=f\"Generate All the RDF triples in URI format you can found from the information below :'{text}'. Write every URI triple in an independent line as JSON. http://dbpedia.org/ontology is allowed for use,Subject is either a URI or a blank node.Predicate is always a URI. Object is either a URI, a blank node or a literal.\",\n",
    "        temperature=0.6,\n",
    "        max_tokens=2000  # be careful with max tokens value. Too high values may result in API errors.\n",
    "    )\n",
    "    triple_text = response.choices[0].text.strip()\n",
    "    print(f\"Generated triples: {triple_text}\")\n",
    "    return triple_text\n",
    "\n",
    "def output_to_json(triples, output_path):\n",
    "    with open(output_path, 'w') as f:\n",
    "        json.dump(triples, f)\n",
    "\n",
    "\n",
    "# def main(input_path, output_path):\n",
    "#     text = extract_information(input_path)\n",
    "#     triples = generate_triples(text)\n",
    "#     output_to_json(triples, output_path)\n",
    "\n",
    "def main(input_path, output_path):\n",
    "    triples = []\n",
    "    with open(input_path, newline='') as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        for row in reader:\n",
    "            triple = generate_triples(row[0])\n",
    "            triples.append(triple)\n",
    "    output_to_json(triples, output_path)\n",
    "\n",
    "main('Data.csv', 'UDITriples.json')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3079f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from py2neo import Graph, Node, Relationship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0253abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to your Neo4j instance\n",
    "graph = Graph(\"http://127.0.0.1:7474\", user=\"neo4j\", password=\"***\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2170ff5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_node(uri):\n",
    "    if 'Disease' in uri:\n",
    "        return 'Disease'\n",
    "    elif 'Symptom' in uri:\n",
    "        return 'Symptom'\n",
    "    elif 'Treatment' in uri:\n",
    "        return 'Treatment'\n",
    "    elif 'Cell' in uri:\n",
    "        return 'Cell'\n",
    "    elif 'Examination' in uri:\n",
    "        return 'Examination'\n",
    "    else:\n",
    "        return 'Resource'\n",
    "\n",
    "\n",
    "# process each triple\n",
    "for triple_data in triples_data:\n",
    "    triple = json.loads(triple_data)\n",
    "\n",
    "    # retrieve the subject, predicate, and object\n",
    "    subject_uri = triple.get('Subject') or triple.get('subject')\n",
    "    predicate_uri = triple.get('Predicate') or triple.get('predicate')\n",
    "    object_uri = triple.get('Object') or triple.get('object')\n",
    "\n",
    "    # log information\n",
    "    print(f'Processing triple: {subject_uri}, {predicate_uri}, {object_uri}')\n",
    "\n",
    "    # determine the category of the subject and object\n",
    "    subject_category = categorize_node(subject_uri)\n",
    "    object_category = categorize_node(object_uri)\n",
    "\n",
    "    # create nodes and relationship\n",
    "    subject = Node(subject_category, uri=subject_uri)\n",
    "    object = Node(object_category, uri=object_uri)\n",
    "    predicate = Relationship.type(predicate_uri)\n",
    "\n",
    "    # check if nodes already exist in the graph, if not create them\n",
    "    graph.merge(subject, subject_category, \"uri\")\n",
    "    graph.merge(object, object_category, \"uri\")\n",
    "\n",
    "    # create the relationship\n",
    "    rel = predicate(subject, object)\n",
    "    graph.merge(rel)\n",
    "\n",
    "    # print logging message\n",
    "    print(f\"Created nodes: {subject_uri} ({subject_category}), {object_uri} ({object_category})\")\n",
    "    print(f\"Created relationship: {subject_uri} -[{predicate_uri}]-> {object_uri}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
